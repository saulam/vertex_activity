{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pk\n",
    "import math\n",
    "import sys, os\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# manually specify the GPUs to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "with open(\"data.p\", \"rb\") as fd:\n",
    "    charges, ini_pos, ini_P, Es, total_charges = pk.load(fd)\n",
    "\n",
    "# all parameters\n",
    "min_charge = charges.min()\n",
    "max_charge = charges.max()\n",
    "min_tCharge = total_charges.min()\n",
    "max_tCharge = total_charges.max()\n",
    "min_pos = ini_pos.min()\n",
    "max_pos = ini_pos.max()\n",
    "min_P = ini_P.min()\n",
    "max_P = ini_P.max()\n",
    "min_E = Es.min()\n",
    "max_E = Es.max()\n",
    "range_pos = max_pos-min_pos\n",
    "range_P = max_P-min_P\n",
    "  \n",
    "source_range = (-1, 1)\n",
    "target_range = (0, 1)\n",
    "\n",
    "min_charge_new = 0\n",
    "max_charge_new = charges.max()\n",
    "\n",
    "m_proton = 938.27208816 # mass of the proton in MeV\n",
    "\n",
    "# dataset\n",
    "class VAdataset(Dataset):\n",
    "    def __init__(self, root, shuffle=False, **kwargs):\n",
    "        '''Initialiser for ProtonVertexDataset class'''\n",
    "        \n",
    "        self.root = root\n",
    "        self.data_files = self.processed_file_names\n",
    "        if shuffle:\n",
    "            random.shuffle(self.data_files) \n",
    "        self.total_events = len(self.data_files)\n",
    "    \n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        return f'{self.root}'\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return sorted(glob(f'{self.processed_dir}/*.npz'))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_events\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = np.load(self.data_files[idx])\n",
    "        \n",
    "        # retrieve input\n",
    "        sparse_image = data['sparse_image'] # array of shape (Nx2) [points vs (1d pos, charge)]\n",
    "        initPosition = data['initPosition'] # array with initial position (x1, y1, z1)\n",
    "        finalPosition = data['finalPosition'] # array with initial position (xN, yN, zN)\n",
    "        initMomentum = data['initMomentum'] # array momentum vector (Px, Py, Pz, E)\n",
    "        \n",
    "        if sparse_image.shape[0] == 0:\n",
    "            del data\n",
    "            return { 'full_image': None,\\\n",
    "                     'initPosition': None,\\\n",
    "                     'finalPosition': None,\\\n",
    "                     'initMomentum': None,\\\n",
    "                     'totalCharge': None}\n",
    "        \n",
    "        # reconstruct the image from sparse points to a 7x7x7 volume\n",
    "        full_image = np.zeros(shape=(7*7*7))\n",
    "        full_image[sparse_image[:,0].astype(int)] = sparse_image[:,1]\n",
    "        totalCharge = full_image.sum()\n",
    "        \n",
    "        # normalise\n",
    "        full_image = np.interp(full_image.ravel(), (min_charge_new, max_charge_new), target_range).reshape(full_image.shape)\n",
    "        initPosition = np.interp(initPosition.ravel(), (min_pos, max_pos), source_range).reshape(initPosition.shape)\n",
    "        initMomentum[:3] = np.interp(initMomentum[:3].ravel(), (min_P, max_P), source_range).reshape(initMomentum[:3].shape)\n",
    "        initMomentum[3] = np.interp(initMomentum[3].ravel(), (min_E, max_E), source_range).reshape(initMomentum[3].shape)\n",
    "        totalCharge = np.interp(totalCharge.ravel(), (min_tCharge, max_tCharge), target_range).reshape(totalCharge.shape)\n",
    "        \n",
    "        del data\n",
    "        return { 'full_image': full_image,\\\n",
    "                 'initPosition': initPosition,\\\n",
    "                 'finalPosition': finalPosition,\\\n",
    "                 'initMomentum': initMomentum,\\\n",
    "                 'totalCharge': totalCharge }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c61b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "dataset = VAdataset(\"images\")\n",
    "ini_pos = ini_pos.reshape(-1)\n",
    "ini_P = ini_P.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77631adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):     \n",
    "    img_batch = np.array([event['full_image'] for event in batch if event['full_image'] is not None])\n",
    "    params_batch = np.array([np.concatenate([event['initPosition'], event['initMomentum']])\\\n",
    "                             for event in batch if event['initPosition'] is not None])\n",
    "    charges = np.array([event['totalCharge'] for event in batch if event['totalCharge'] is not None])\n",
    "    \n",
    "    img_batch = torch.tensor(img_batch).float()\n",
    "    params_batch = torch.tensor(params_batch).float()\n",
    "    charges = torch.tensor(charges).float()\n",
    "    \n",
    "    return img_batch, params_batch, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdcf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "fulllen = len(dataset)\n",
    "\n",
    "train_len = int(fulllen*0.6)\n",
    "val_len = int(fulllen*0.1)\n",
    "test_len = fulllen-train_len-val_len\n",
    "train_set, val_set, test_set = random_split(dataset, [train_len, val_len, test_len],\n",
    "                                            generator=torch.Generator().manual_seed(7))\n",
    "\n",
    "train_loader = DataLoader(train_set, collate_fn=collate_fn, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, collate_fn=collate_fn, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "test_loader = DataLoader(test_set, collate_fn=collate_fn, batch_size=batch_size, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "vol_idx = np.moveaxis(np.indices((7, 7, 7)), 0, -1) # indexes volume\n",
    "vol_idx = np.interp(vol_idx.ravel(), (0, 6), source_range).reshape(vol_idx.shape)\n",
    "vol_idx = torch.FloatTensor(vol_idx)\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, label_size, noise_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.label_size = label_size\n",
    "        self.noise_size = noise_size\n",
    "        \n",
    "        # linear projection for the pos + noise + labels\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.d_model1 = 32\n",
    "        self.d_model2 = self.d_model1//2\n",
    "        self.d_model3 = self.d_model2//2\n",
    "        \n",
    "        # linear mappings\n",
    "        self.project_px = nn.Linear(1, self.d_model1-3)\n",
    "        self.project_py = nn.Linear(1, self.d_model1-3)\n",
    "        self.project_pz = nn.Linear(1, self.d_model1-3)\n",
    "        self.project_e = nn.Linear(1, self.d_model1-3)\n",
    "        self.project_x = nn.Linear(1, self.d_model1-3)\n",
    "        self.project_y = nn.Linear(1, self.d_model1-3)\n",
    "        self.project_z = nn.Linear(1, self.d_model1-3)\n",
    "        self.map1 = nn.Linear(self.d_model1*2, 7*(self.d_model2-3))\n",
    "        self.map2 = nn.Linear(self.d_model1*2, 7*(self.d_model2-3))\n",
    "        \n",
    "        self.map_enc1 = nn.Linear(self.d_model1, self.d_model1)\n",
    "        self.map_enc2 = nn.Linear(self.d_model2, self.d_model1)\n",
    "        self.map_enc3 = nn.Linear(self.d_model2, self.d_model1)\n",
    "           \n",
    "        # Tranformer encoders\n",
    "        encoder_layers1 = TransformerEncoderLayer(d_model=self.d_model1,\n",
    "                                                 nhead=self.d_model1//8,\n",
    "                                                 dim_feedforward=self.d_model1*2,\n",
    "                                                 dropout=dropout,\n",
    "                                                 batch_first=True # very important\n",
    "                                                 )\n",
    "        self.encoder1 = TransformerEncoder(encoder_layers1, 2) # model\n",
    "        \n",
    "        encoder_layers2 = TransformerEncoderLayer(d_model=self.d_model1,\n",
    "                                                 nhead=self.d_model1//8,\n",
    "                                                 dim_feedforward=self.d_model1*2,\n",
    "                                                 dropout=dropout,\n",
    "                                                 batch_first=True # very important\n",
    "                                                 )\n",
    "        self.encoder2 = TransformerEncoder(encoder_layers2, 4) # model\n",
    "        \n",
    "        encoder_layers3 = TransformerEncoderLayer(d_model=self.d_model1,\n",
    "                                                 nhead=self.d_model1//8,\n",
    "                                                 dim_feedforward=self.d_model1*2,\n",
    "                                                 dropout=dropout,\n",
    "                                                 batch_first=True # very important\n",
    "                                                 )\n",
    "        self.encoder3 = TransformerEncoder(encoder_layers3, 8) # model\n",
    "        \n",
    "        # Final decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "                                     #nn.LeakyReLU(0.2),\n",
    "                                     nn.Linear(self.d_model1, 1),\n",
    "                                     #nn.Tanh()\n",
    "                                     #nn.ReLU()\n",
    "                                     nn.Sigmoid()\n",
    "                                    )\n",
    "    \n",
    "    def forward(self, labels, noise):\n",
    "        \n",
    "        # Reshape labels\n",
    "        labels = labels.view(-1, 7, 1)\n",
    "        \n",
    "        # project labels\n",
    "        proj_px = self.project_px(labels[:, 0])\n",
    "        proj_py = self.project_px(labels[:, 1])\n",
    "        proj_pz = self.project_px(labels[:, 2])\n",
    "        proj_e = self.project_px(labels[:, 3])\n",
    "        proj_x = self.project_px(labels[:, 4])\n",
    "        proj_y = self.project_px(labels[:, 5])\n",
    "        proj_z = self.project_px(labels[:, 6])\n",
    "        \n",
    "        # stack labels back + pos encoding\n",
    "        proj_labels = torch.stack([proj_px, proj_py, proj_pz, proj_e,\\\n",
    "                                   proj_x, proj_y, proj_z], dim=1)\n",
    "        x = proj_labels\n",
    "\n",
    "        # Transformer 1\n",
    "        x = self.dropout(x)\n",
    "        pos = vol_idx[3,3,:,:].repeat(x.shape[0],1,1).view(-1,7,3).to(device)\n",
    "        x = torch.cat([pos, x], dim=2) # add pos\n",
    "        x = self.map_enc1(x)\n",
    "        x = self.encoder1(x)\n",
    "        \n",
    "        # add noise\n",
    "        z = torch.normal(0, 0.5, size=x.shape).to(device)        \n",
    "        xz = torch.cat([x,z], dim=2)\n",
    "        x = self.map1(xz).view(-1, 7*7, self.d_model2-3)\n",
    "        \n",
    "        # Transformer 2\n",
    "        x = self.dropout(x)\n",
    "        pos = vol_idx[3,:,:,:].repeat(x.shape[0],1,1,1).view(-1,7*7,3).to(device)\n",
    "        x = torch.cat([pos, x], dim=2) # add pos\n",
    "        x = self.map_enc2(x)\n",
    "        x = self.encoder2(x)\n",
    "              \n",
    "        # add noise\n",
    "        z = torch.normal(0, 0.5, size=x.shape).to(device)\n",
    "        xz = torch.cat([x,z], dim=2)        \n",
    "        x = self.map2(xz).view(-1, 7*7*7, self.d_model2-3)\n",
    "        \n",
    "        # Transformer 3\n",
    "        x = self.dropout(x)\n",
    "        pos = vol_idx.repeat(x.shape[0],1,1,1,1).view(-1,7*7*7,3).to(device)\n",
    "        x = torch.cat([pos, x], dim=2) # add pos\n",
    "        x = self.map_enc3(x)\n",
    "        x = self.encoder3(x)\n",
    "        \n",
    "        # Generator out\n",
    "        out = self.decoder(x)\n",
    "    \n",
    "class PoissonLikelihood_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Poisson Likelihood loss function\n",
    "        Email: jchen245@jhmi.edu\n",
    "        Date: 02/21/2021\n",
    "        :param max_val: the maximum value of the target.\n",
    "        '''\n",
    "        super(PoissonLikelihood_loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.view(y_pred.shape[0], -1)\n",
    "        y_true = y_true.view(y_true.shape[0], -1)\n",
    "\n",
    "        \"\"\"Custom loss function for Poisson model.\"\"\"\n",
    "        loss=torch.mean(y_pred-y_true*torch.log(y_pred+eps))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa85e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('torch version:',torch.__version__)\n",
    "print('device:', device)\n",
    "\n",
    "img_size = 7\n",
    "label_size = 6\n",
    "noise_size = 3\n",
    "lambda_gp = 10\n",
    "dropout = 0.2\n",
    "eps = 1e-6\n",
    "noise_type = \"normal\"\n",
    "\n",
    "generator = Generator(label_size, noise_size).to(device)\n",
    "\n",
    "generator_total_params = sum(p.numel() for p in generator.parameters() if p.requires_grad)\n",
    "print(generator)\n",
    "print(\"total trainable params: {} (generator).\".format(generator_total_params))\n",
    "\n",
    "lossf = PoissonLikelihood_loss()\n",
    "\n",
    "# Training\n",
    "epochs = 10  # Train epochs\n",
    "learning_rate = 0.0002#1e-4\n",
    "betas = (0.9, 0.98)#(0.5, 0.999)\n",
    "\n",
    "# optmiisers\n",
    "#g_optimizer = torch.optim.RMSprop(generator.parameters(), lr=learning_rate)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Generator with Wasserstein Loss\n",
    "def generator_train_step(batch_size, generator, g_optimizer, real_images, labels, charges):\n",
    "    \n",
    "    # init gradient\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # labels\n",
    "    real_labels = labels.to(device)\n",
    "    charges = charges.to(device)\n",
    "    \n",
    "    # fake\n",
    "    z = torch.normal(0, 0.5, size=(batch_size, img_size, img_size, img_size, noise_size)).to(device)\n",
    "    #z = torch.distributions.uniform.Uniform(-1,1).sample([batch_size, img_size, img_size, img_size, noise_size]).to(device)\n",
    "    fake_data = generator(real_labels, z)\n",
    "    \n",
    "    # real\n",
    "    real_data = real_images.to(device)\n",
    "    \n",
    "    # Generator loss\n",
    "    w_loss = lossf(fake_data, real_data)\n",
    "    w_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return w_loss\n",
    "\n",
    "def generator_test_step(batch_size, generator, real_images, labels):\n",
    "    \n",
    "    generator.eval()\n",
    "    \n",
    "    # init gradient\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # labels\n",
    "    real_labels = labels.to(device)\n",
    "    \n",
    "    # fake\n",
    "    z = torch.normal(0, 0.5, size=(batch_size, img_size, img_size, img_size, noise_size)).to(device)\n",
    "    fake_data = generator(real_labels, z)\n",
    "    \n",
    "    # real\n",
    "    real_data = real_images.to(device)\n",
    "    \n",
    "    # Generator loss\n",
    "    w_loss = lossf(fake_data, real_data)\n",
    "    \n",
    "    return w_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event(X, Y, labels, elev=20, azim=20, add_projs=False):\n",
    "    \n",
    "    nevents = len(X)\n",
    "        \n",
    "    # start plot\n",
    "    fig = plt.figure(figsize=(nevents*18, nevents*17))\n",
    "    \n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    color = np.array(['#7A88CCC0'])\n",
    "    edgecolor = '1.0'\n",
    "        \n",
    "    for event in range(nevents):\n",
    "        x = X[event].reshape(img_size,img_size,img_size)\n",
    "        y = Y[event].reshape(img_size,img_size,img_size)\n",
    "        x[x<min_charge_plot] = 0\n",
    "        y[y<min_charge_plot] = 0\n",
    "\n",
    "        # fill the detector with reco hits and shrink\n",
    "        detector1 = np.zeros((7, 7, 7), dtype=bool)\n",
    "        detector_hitcharges1 = x\n",
    "        colors1 = np.empty((7,7,7,4), dtype=object)\n",
    "\n",
    "        detector2 = np.zeros((7, 7, 7), dtype=bool)\n",
    "        detector_hitcharges2 = y\n",
    "        colors2 = np.empty((7,7,7,4), dtype=object)\n",
    "\n",
    "        # set colors based on hit charge\n",
    "        norm = matplotlib.colors.Normalize(vmin=min_charge, vmax=max_charge)\n",
    "        cmap = cm.YlOrRd\n",
    "        m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "        for i in range(detector1.shape[0]):\n",
    "            for j in range(detector1.shape[1]):\n",
    "                for k in range(detector1.shape[2]):\n",
    "                    colors1[i,j,k] = m.to_rgba(detector_hitcharges1[i,j,k])\n",
    "                    colors2[i,j,k] = m.to_rgba(detector_hitcharges2[i,j,k])\n",
    "    \n",
    "        to_plot = [x, y]\n",
    "        for i in range(len(to_plot)):\n",
    "            ax = fig.add_subplot(nevents, nevents, i*nevents+ event+1, projection='3d')\n",
    "\n",
    "            # voxels volume\n",
    "            sc = ax.voxels(to_plot[i], facecolors=colors1, edgecolor=edgecolor, alpha=1.0)\n",
    "\n",
    "            #ax.tick_params(axis='both', which='minor', labelsize=20, length=0)\n",
    "            ax.set_xlabel('X [cube]', labelpad=50, fontsize=45)\n",
    "            ax.set_ylabel('Z [cube]', labelpad=50, fontsize=45)\n",
    "            ax.set_zlabel('Y [cube]', labelpad=50, fontsize=45)\n",
    "            \n",
    "            ini_KE = np.interp(labels[event,-1], source_range, (min_E, max_E)) - m_proton\n",
    "\n",
    "            # ticks\n",
    "            ax.set_title(\"Total charge: {0:.2f} p.e.\\n[KE of {1:.2f} MeV]\".format(to_plot[i].sum(),\\\n",
    "                                                                                 ini_KE), fontsize=50)\n",
    "            ax.set_xticks(np.arange(0.5, 7, 1.), minor=True, length=0, width=0, grid_alpha=0)\n",
    "            ax.set_xticklabels([str(x) for x in range(1,8)], minor=True, size=25)\n",
    "            ax.set_xticklabels([], minor=False)\n",
    "            ax.set_yticklabels([], minor=False)\n",
    "            ax.set_yticks(np.arange(0.5, 7, 1.), minor=True, length=0, width=0)\n",
    "            ax.set_yticklabels([str(x) for x in range(1,8)], minor=True, size=25)\n",
    "            ax.set_zticklabels([], minor=False)\n",
    "            ax.set_zticks(np.arange(0.5, 7, 1.), minor=True)\n",
    "            ax.set_zticklabels([str(x) for x in range(1,8)], minor=True, size=25)\n",
    "\n",
    "            # change camera angle\n",
    "            ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "            ax.grid(False)\n",
    "            \n",
    "    # colorbar\n",
    "    fig.subplots_adjust(right=0.925)\n",
    "    cbar_ax = fig.add_axes([0.95, 0.70, 0.01, 0.15]) # left, botton, width, height\n",
    "    cbar = fig.colorbar(m, cax=cbar_ax, fraction=0.020)\n",
    "    #cbar = plt.colorbar(m, fraction=0.020, pad=0.2)\n",
    "    cbar.set_label('# of p.e.', rotation=90, labelpad=19, fontsize=40)\n",
    "    cbar.ax.tick_params(labelsize=35)\n",
    "            \n",
    "    #fig.tight_layout()\n",
    "    #plt.subplots_adjust(top=0.85)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5704723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disable = False\n",
    "load = False\n",
    "save = True\n",
    "\n",
    "min_charge_plot = min_charge\n",
    "#min_charge_plot = 30\n",
    "\n",
    "g_losses = []\n",
    "g_losses_real = []\n",
    "g_losses_fake = []\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "if load:\n",
    "    print(\"Loading saved model...\")\n",
    "    epoch, iteration = 1, 500\n",
    "    checkpoint = torch.load(\"models/gen_{}_{}\".format(epoch, iteration))\n",
    "    generator.load_state_dict(checkpoint['g_state_dict'])\n",
    "    g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']+1\n",
    "    g_losses = checkpoint['g_losses'].tolist()\n",
    "\n",
    "for epoch in range(epoch, epochs):\n",
    "    \n",
    "    print('Starting epoch {}...'.format(epoch))\n",
    "    \n",
    "    train_loss, val_loss = 0., 0.\n",
    "    \n",
    "    batch_size = train_loader.batch_size\n",
    "    n_batches = int(math.ceil(len(train_loader.dataset)/batch_size))\n",
    "    t = tqdm.tqdm(enumerate(train_loader), total=n_batches, disable=disable)\n",
    "    \n",
    "    for ite, (images, labels, charges) in t:\n",
    "        \n",
    "        # Train data\n",
    "        real_images = images\n",
    "        \n",
    "        p = float(ite + (epoch) * len(train_loader)) / (epochs) / len(train_loader)\n",
    "        lambda_pe = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        \n",
    "        # Set generator train\n",
    "        generator.train()\n",
    "        \n",
    "        # Train generator\n",
    "        g_loss = generator_train_step(len(real_images),\\\n",
    "                                       generator, g_optimizer,\\\n",
    "                                       real_images, labels, charges)\n",
    "        \n",
    "        t.set_description(\"g_loss = {0:.5f}\".format(g_loss.item()))\n",
    "        \n",
    "        train_loss += g_loss.item()\n",
    "        \n",
    "        if ite%50==0:\n",
    "            g_losses.append(g_loss.item())\n",
    "            #g_losses_real.append(real_loss.item())\n",
    "            #g_losses_fake.append(fake_loss.item())\n",
    "            \n",
    "        if ite%500==0 and ite>0:\n",
    "            if not disable:    \n",
    "                # Set generator eval\n",
    "                generator.eval()\n",
    "\n",
    "                true_images = []\n",
    "                pred_images = []\n",
    "\n",
    "                for i, (images, labels, charges) in enumerate(valid_loader):\n",
    "\n",
    "                    print(i)\n",
    "\n",
    "                    # Building z\n",
    "                    z = torch.normal(0, 0.5, size=(len(images), img_size, img_size, img_size, noise_size)).to(device)\n",
    "                    #z = torch.distributions.uniform.Uniform(-1,1).sample([len(images), img_size, img_size, img_size, noise_size]).to(device)\n",
    "                    sample_images = generator(labels.to(device), z).data.cpu()\n",
    "\n",
    "                    for j in range(len(images)):\n",
    "                        true_image = images[j].numpy()\n",
    "                        pred_image = sample_images[j].numpy()\n",
    "                        true_image = np.interp(true_image.ravel(), target_range, (min_charge_new, max_charge_new)).reshape(true_image.shape)\n",
    "                        pred_image = np.interp(pred_image.ravel(), target_range, (min_charge_new, max_charge_new)).reshape(pred_image.shape)\n",
    "                        #true_image = prepro.inverse_transform(true_image.reshape(-1,1))\n",
    "                        #pred_image = prepro.inverse_transform(pred_image.reshape(-1,1))\n",
    "                        true_images.append(true_image)\n",
    "                        pred_images.append(pred_image)\n",
    "\n",
    "                    break\n",
    "\n",
    "                plot_event(true_images[:7], pred_images[:7], labels[:7])\n",
    "                \n",
    "            if save:\n",
    "                torch.save({\n",
    "                           'epoch': epoch,\n",
    "                           'g_state_dict': generator.state_dict(),\n",
    "                           'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
    "                           'g_losses': np.array(g_losses),\n",
    "                           }, \"models/gen_{}_{}\".format(epoch, ite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2780289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
